# Cliff Walkinig problem

![Screen Shot 2023-05-04 at 5 15 12 PM](https://user-images.githubusercontent.com/115062425/236355653-e1078cc0-3ddb-4f9b-993e-50762a23ff49.png)

This folder of codes try to train an agent to walk safely without crashing into the cliff. 

## Implementation:

The implementation is split into two parts:

step1. [ðŸ”—](https://github.com/yoyostudy/rl_ua/blob/main/code/C2_A1_A2_CliffWalking/C2_A1_CliffWalking_PolicyEvaluation/Policy%20Evaluation%20with%20Temporal%20Difference%20Learning/assignment%202.ipynb) Developed a deterministic Markov Decision Process model for the Cliff Walking problem with discrete
state and action space, and implemented a reward function and environment class in Python, resulting
in an effective platform for training and optimizing reinforcement learning algorithms.

step2. [ðŸ”—](https://github.com/yoyostudy/rl_ua/blob/main/code/C2_A1_A2_CliffWalking/C2_A2_Qlearning_SARSA_CliffWalking/Q-Learning%20and%20Expected%20Sarsa/assignment.ipynb) Implemented TD-based Q-learning and Expected SARSA agents with $\epsilon$ greedy action selection and
evaluated their performance on the Cliff World problem, observing that both algorithms achieved a
convergent maximum sum of rewards.

## Training Results:

![Screen Shot 2023-05-04 at 5 21 38 PM](https://user-images.githubusercontent.com/115062425/236356165-4ee2159e-cf96-43ea-9f39-5dc596233fb9.png)

![Screen Shot 2023-05-04 at 5 21 51 PM](https://user-images.githubusercontent.com/115062425/236356186-95525db0-8534-449e-82f6-791ed676e92b.png)
