# Cliff Walkinig problem

![Screen Shot 2023-05-04 at 5 15 12 PM](https://user-images.githubusercontent.com/115062425/236355653-e1078cc0-3ddb-4f9b-993e-50762a23ff49.png)

This folder of codes try to train an agent to walk safely without crashing into the cliff. 

The implementation is split into two parts:

[ðŸ”—](https://github.com/yoyostudy/rl_ua/blob/main/code/C2_A1_A2_CliffWalking/C2_A1_CliffWalking_PolicyEvaluation/Policy%20Evaluation%20with%20Temporal%20Difference%20Learning/assignment%202.ipynb) Developed a deterministic Markov Decision Process model for the Cliff Walking problem with discrete
state and action space, and implemented a reward function and environment class in Python, resulting
in an effective platform for training and optimizing reinforcement learning algorithms.

[ðŸ”—](https://github.com/yoyostudy/rl_ua/blob/main/code/C2_A1_A2_CliffWalking/C2_A2_Qlearning_SARSA_CliffWalking/Q-Learning%20and%20Expected%20Sarsa/assignment.ipynb) Implemented TD-based Q-learning and Expected SARSA agents with $\epsilon-$greedy action selection and
evaluated their performance on the Cliff World problem, observing that both algorithms achieved a
convergent maximum sum of rewards.
